{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ee7436",
   "metadata": {},
   "source": [
    "# Agent C: SQL Generator\n",
    "`Generates an SQL query tailored to natural language query and selected schema.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6181a699",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "1. [OpenAI Setup](#OpenAI-Setup)\n",
    "2. [Testing Setup](#testing-setup) \n",
    "3. [Generate SQL](#generate-sql)\n",
    "4. [Test Results](#Test-results)\n",
    "5. [Putting it all together](#Putting-it-all-together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e479c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import openai\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0073abff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/lainemulvay/Desktop/Projects/UNI/Capstone/Explainable-Query-Interface-for-Relational-Databases\n",
      "Notebook folder: /Users/lainemulvay/Desktop/Projects/UNI/Capstone/Explainable-Query-Interface-for-Relational-Databases\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path(__file__).parent.parent.parent if '__file__' in globals() else Path.cwd().parent.parent.parent  \n",
    "sys.path.append(PROJECT_ROOT)\n",
    "os.chdir(PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4869fc59",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4031eaf1",
   "metadata": {},
   "source": [
    "## OpenAI Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2052e34d",
   "metadata": {},
   "source": [
    "Import OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8047561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key used: sk-pr****\n"
     ]
    }
   ],
   "source": [
    "from src import config\n",
    "\n",
    "print(\"OpenAI API key used:\", config.OPENAI_API_KEY[:5] + \"****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36cc2bf",
   "metadata": {},
   "source": [
    "make a simple chat completion request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab8b597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# set your API key from .env\n",
    "openai.api_key = config.OPENAI_API_KEY\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
    ")\n",
    "\n",
    "# print the model's reply\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790dfcc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2c2e85",
   "metadata": {},
   "source": [
    "# Testing Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc82163b",
   "metadata": {},
   "source": [
    "### Setting up db_id, natural language query and sql answers for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4dafa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   db_id                                              query  \\\n",
      "0  department_management         SELECT count(*) FROM head WHERE age  >  56   \n",
      "1  department_management  SELECT name ,  born_state ,  age FROM head ORD...   \n",
      "2  department_management  SELECT creation ,  name ,  budget_in_billions ...   \n",
      "3  department_management  SELECT max(budget_in_billions) ,  min(budget_i...   \n",
      "4  department_management  SELECT avg(num_employees) FROM department WHER...   \n",
      "\n",
      "                                            question  \n",
      "0  How many heads of the departments are older th...  \n",
      "1  List the name, born state and age of the heads...  \n",
      "2  List the creation year, name and budget of eac...  \n",
      "3  What are the maximum and minimum budget of the...  \n",
      "4  What is the average number of employees of the...  \n",
      "Saved simplified queries to /data/interim\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "SQL_DATA_PATH = PROJECT_ROOT / \"data\" / \"spider_data\" / \"train_spider.json\"  \n",
    "OUTPUT_PATH = PROJECT_ROOT / \"data\" / \"interim\" / \"query_sql_answers.json\"\n",
    "\n",
    "\n",
    "def load_sql_dataset(file_path: Union[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the Spider dataset (JSON with a list of records) and return a DataFrame with \n",
    "    db_id, query, question.\n",
    "    \"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)  # load entire JSON list\n",
    "\n",
    "    records = [\n",
    "        {\n",
    "            \"db_id\": rec.get(\"db_id\"),\n",
    "            \"query\": rec.get(\"query\"),\n",
    "            \"question\": rec.get(\"question\")\n",
    "        }\n",
    "        for rec in data\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "df = load_sql_dataset(SQL_DATA_PATH)\n",
    "print(df.head())\n",
    "\n",
    "# Save to JSON\n",
    "OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_json(OUTPUT_PATH, orient=\"records\", indent=2)\n",
    "print(\"Saved simplified queries to /data/interim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f32465",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef50aee",
   "metadata": {},
   "source": [
    "## Generate SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adba8883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook folder added to sys.path: /Users/lainemulvay/Desktop/Projects/UNI/Capstone/Explainable-Query-Interface-for-Relational-Databases/notebooks/agent-development/Laine\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    " \n",
    "NOTEBOOK_FOLDER = Path.cwd() / \"notebooks\" / \"agent-development\" / \"Laine\" # CHANGE WHEN MOVED INTO A SCRIPT\n",
    "sys.path.append(str(NOTEBOOK_FOLDER))\n",
    "print(\"Notebook folder added to sys.path:\", NOTEBOOK_FOLDER)\n",
    "\n",
    "from agent_utils import get_schema_text, load_schemas, schema_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f3ba79",
   "metadata": {},
   "source": [
    "#### Get the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5db1f0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classroom(building, room_number, capacity)\n",
      "department(dept_name, building, budget)\n",
      "course(course_id, title, dept_name, credits)\n",
      "instructor(ID, name, dept_name, salary)\n",
      "section(course_id, sec_id, semester, year, building, room_number, time_slot_id)\n",
      "teaches(ID, course_id, sec_id, semester, year)\n",
      "student(ID, name, dept_name, tot_cred)\n",
      "takes(ID, course_id, sec_id, semester, year, grade)\n",
      "advisor(s_ID, i_ID)\n",
      "time_slot(time_slot_id, day, start_hr, start_min, end_hr, end_min)\n",
      "prereq(course_id, prereq_id)\n"
     ]
    }
   ],
   "source": [
    "SCHEMA_PATH = PROJECT_ROOT / \"data\" / \"spider_data\" / \"tables.json\"\n",
    "schemas = load_schemas(SCHEMA_PATH)\n",
    "\n",
    "db_id = \"college_2\"\n",
    "print(get_schema_text(db_id, schemas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b2fa6",
   "metadata": {},
   "source": [
    "#### Feed the question and schema to LLM, get back query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13b8a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_schema_text(db_id: str, schemas: dict) -> str:\n",
    "    \"\"\"\n",
    "    Return the schema text for a given db_id.\n",
    "    \"\"\"\n",
    "    if db_id not in schemas:\n",
    "        raise ValueError(f\"db_id '{db_id}' not found in schemas\")\n",
    "    return schema_text(schemas[db_id])\n",
    "\n",
    "def generate_sql_from_llm(db_id: str, question: str, schemas: dict, model: str=\"gpt-4\") -> str:\n",
    "    \"\"\"\n",
    "    Generate a SQL query using GPT from a db_id and a natural language question.\n",
    "    \"\"\"\n",
    "    schema_str = get_schema_text(db_id, schemas)\n",
    "    prompt = f\"\"\"\n",
    "You are an SQL expert. Given the following database schema:\n",
    "\n",
    "{schema_str}\n",
    "\n",
    "Write a SQL query that answers the following question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Only return the SQL query, nothing else.\n",
    "\"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    sql_query = response.choices[0].message.content.strip()\n",
    "    return sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4134d597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(*) \n",
      "FROM head \n",
      "WHERE age > 56;\n"
     ]
    }
   ],
   "source": [
    "db_id = \"department_management\"\n",
    "question = \"How many heads of the departments are older than 56 ?\"\n",
    "\n",
    "sql_generated = generate_sql_from_llm(db_id, question, schemas)\n",
    "print(sql_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f6a65",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193d52c",
   "metadata": {},
   "source": [
    "## Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00c40132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT count(*) FROM head WHERE age  >  56\n"
     ]
    }
   ],
   "source": [
    "QUERY_JSON_PATH = PROJECT_ROOT / \"data\" / \"interim\" / \"query_sql_answers.json\"\n",
    "\n",
    "# Load the DataFrame once\n",
    "df_queries = pd.read_json(QUERY_JSON_PATH)\n",
    "\n",
    "def get_result(db_id: str, question: str) -> str:\n",
    "    \"\"\"\n",
    "    Given a db_id and question, return the corresponding SQL query from the dataset.\n",
    "    \"\"\"\n",
    "    match = df_queries[\n",
    "        (df_queries[\"db_id\"] == db_id) & \n",
    "        (df_queries[\"question\"] == question)\n",
    "    ]\n",
    "    \n",
    "    if match.empty:\n",
    "        raise ValueError(f\"No query found for db_id='{db_id}' and question='{question}'\")\n",
    "    \n",
    "    # Return the first match (there should only be one)\n",
    "    return match.iloc[0][\"query\"]\n",
    "\n",
    "db_id = \"department_management\"\n",
    "question = \"How many heads of the departments are older than 56 ?\"\n",
    "\n",
    "true_sql_query = get_result(db_id, question)\n",
    "print(true_sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f180cf7",
   "metadata": {},
   "source": [
    "This will not match the LLM's generated SQL beucase it is formatted differently, despide still having the correct content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2a86000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(sql_generated == true_sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b5ab0e",
   "metadata": {},
   "source": [
    "Therefore we account for the different formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d54f6a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def normalise(sql: str) -> str:\n",
    "    # Lowercase\n",
    "    sql = sql.lower()\n",
    "    # Remove extra whitespace\n",
    "    sql = re.sub(r\"\\s+\", \" \", sql)\n",
    "    # Strip leading/trailing spaces and optional trailing semicolon\n",
    "    sql = sql.strip().rstrip(\";\")\n",
    "    return sql\n",
    "\n",
    "def test_llm_query(query1: str, query2: str) -> bool:\n",
    "    return normalise(query1) == normalise(query2)\n",
    "\n",
    "# Example usage\n",
    "test_answer = \"SELECT count(*) FROM head WHERE age  >  56\"\n",
    "llm_answer = \"SELECT COUNT(*) \\nFROM head \\nWHERE age > 56;\"\n",
    "\n",
    "print(test_llm_query(true_sql_query, sql_generated))  # True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f322c986",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d87bc",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a92f4",
   "metadata": {},
   "source": [
    "look at the json file ( run this for a random n quesitons - randomly picked from json file)\n",
    "take the db_id and query\n",
    "get the schema and give it to LLM to generate \n",
    "test the LLms answer to the acutal answer and see if its true or not\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcd86a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DB: medicine_enzyme_interaction\n",
      "Question: What are the ids and trade names of the medicine that can interact with at least 3 enzymes?\n",
      "True SQL: SELECT T1.id ,  T1.trade_name FROM medicine AS T1 JOIN medicine_enzyme_interaction AS T2 ON T2.medicine_id  =  T1.id GROUP BY T1.id HAVING COUNT(*)  >=  3\n",
      "LLM SQL:  SELECT m.id, m.Trade_Name\n",
      "FROM medicine m\n",
      "JOIN medicine_enzyme_interaction mei ON m.id = mei.medicine_id\n",
      "GROUP BY m.id, m.Trade_Name\n",
      "HAVING COUNT(mei.enzyme_id) >= 3\n",
      "Match? False\n",
      "================================================================================\n",
      "DB: student_1\n",
      "Question: Report the number of students in each classroom.\n",
      "True SQL: SELECT classroom ,  count(*) FROM list GROUP BY classroom\n",
      "LLM SQL:  SELECT Classroom, COUNT(*) as NumberOfStudents\n",
      "FROM list\n",
      "GROUP BY Classroom\n",
      "Match? False\n",
      "================================================================================\n",
      "DB: chinook_1\n",
      "Question: Count the number of customers that have an email containing \"gmail.com\".\n",
      "True SQL: SELECT COUNT(*) FROM CUSTOMER WHERE Email LIKE \"%gmail.com%\"\n",
      "LLM SQL:  SELECT COUNT(*) \n",
      "FROM Customer \n",
      "WHERE Email LIKE '%gmail.com%';\n",
      "Match? False\n",
      "================================================================================\n",
      "DB: soccer_1\n",
      "Question: List all country and league names.\n",
      "True SQL: SELECT T1.name ,  T2.name FROM Country AS T1 JOIN League AS T2 ON T1.id  =  T2.country_id\n",
      "LLM SQL:  SELECT c.name AS country_name, l.name AS league_name \n",
      "FROM Country c \n",
      "JOIN League l \n",
      "ON c.id = l.country_id;\n",
      "Match? False\n",
      "================================================================================\n",
      "DB: shop_membership\n",
      "Question: Show card number, name, and hometown for all members in a descending order of level.\n",
      "True SQL: SELECT card_number ,  name ,  hometown FROM member ORDER BY LEVEL DESC\n",
      "LLM SQL:  SELECT Card_Number, Name, Hometown\n",
      "FROM member\n",
      "ORDER BY Level DESC;\n",
      "Match? False\n",
      "================================================================================\n",
      "DB: behavior_monitoring\n",
      "Question: Find the first names of teachers whose email address contains the word \"man\".\n",
      "True SQL: SELECT first_name FROM Teachers WHERE email_address LIKE '%man%'\n",
      "LLM SQL:  SELECT first_name \n",
      "FROM Teachers \n",
      "WHERE email_address LIKE '%man%';\n",
      "Match? True\n",
      "================================================================================\n",
      "DB: restaurant_1\n",
      "Question: List all students' first names and last names who majored in 600.\n",
      "True SQL: SELECT Fname , Lname FROM Student WHERE Major  =  600;\n",
      "LLM SQL:  SELECT Fname, LName \n",
      "FROM Student\n",
      "WHERE Major = 600;\n",
      "Match? False\n",
      "================================================================================\n",
      "DB: department_store\n",
      "Question: What are the ids of suppliers which have an average amount purchased of above 50000 or below 30000?\n",
      "True SQL: SELECT supplier_id FROM Product_Suppliers GROUP BY supplier_id HAVING avg(total_amount_purchased)  >  50000 OR avg(total_amount_purchased)  <  30000\n",
      "LLM SQL:  SELECT supplier_id\n",
      "FROM Product_Suppliers\n",
      "GROUP BY supplier_id\n",
      "HAVING AVG(total_amount_purchased) > 50000 OR AVG(total_amount_purchased) < 30000;\n",
      "Match? True\n",
      "================================================================================\n",
      "DB: products_gen_characteristics\n",
      "Question: What are the names, color descriptions, and product descriptions for products in the 'Herbs' category?\n",
      "True SQL: SELECT T1.product_name ,  T2.color_description ,  T1.product_description FROM products AS T1 JOIN Ref_colors AS T2 ON T1.color_code  =  T2.color_code WHERE product_category_code  =  \"Herbs\"\n",
      "LLM SQL:  SELECT p.product_name, c.color_description, p.product_description\n",
      "FROM Products p\n",
      "JOIN Ref_Colors c ON p.color_code = c.color_code\n",
      "JOIN Ref_Product_Categories pc ON p.product_category_code = pc.product_category_code\n",
      "WHERE pc.product_category_description = 'Herbs';\n",
      "Match? False\n",
      "================================================================================\n",
      "DB: customers_and_products_contacts\n",
      "Question: How many products have a price higher than the average?\n",
      "True SQL: SELECT count(*) FROM products WHERE product_price  >  (SELECT avg(product_price) FROM products)\n",
      "LLM SQL:  SELECT COUNT(*) FROM Products\n",
      "WHERE product_price > (SELECT AVG(product_price) FROM Products);\n",
      "Match? True\n",
      "\n",
      "Summary:\n",
      "                             db_id  match\n",
      "0      medicine_enzyme_interaction  False\n",
      "1                        student_1  False\n",
      "2                        chinook_1  False\n",
      "3                         soccer_1  False\n",
      "4                  shop_membership  False\n",
      "5              behavior_monitoring   True\n",
      "6                     restaurant_1  False\n",
      "7                 department_store   True\n",
      "8     products_gen_characteristics  False\n",
      "9  customers_and_products_contacts   True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load queries JSON (already done above, but included for clarity)\n",
    "QUERY_JSON_PATH = PROJECT_ROOT / \"data\" / \"interim\" / \"query_sql_answers.json\"\n",
    "df_queries = pd.read_json(QUERY_JSON_PATH)\n",
    "\n",
    "def run_random_tests(n: int = 5, model: str = \"gpt-4\"):\n",
    "    \"\"\"\n",
    "    Run n random tests comparing LLM-generated SQL against ground-truth SQL.\n",
    "    \"\"\"\n",
    "    # Sample n random rows\n",
    "    sample_rows = df_queries.sample(n, random_state=random.randint(0, 9999))\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for _, row in sample_rows.iterrows():\n",
    "        db_id = row[\"db_id\"]\n",
    "        question = row[\"question\"]\n",
    "        true_query = row[\"query\"]\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"DB: {db_id}\")\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"True SQL: {true_query}\")\n",
    "\n",
    "        try:\n",
    "            # Generate SQL from LLM\n",
    "            llm_query = generate_sql_from_llm(db_id, question, schemas, model=model)\n",
    "            print(f\"LLM SQL:  {llm_query}\")\n",
    "\n",
    "            # Compare normalised queries\n",
    "            is_match = test_llm_query(true_query, llm_query)\n",
    "            print(f\"Match? {is_match}\")\n",
    "\n",
    "            results.append({\n",
    "                \"db_id\": db_id,\n",
    "                \"question\": question,\n",
    "                \"true_query\": true_query,\n",
    "                \"llm_query\": llm_query,\n",
    "                \"match\": is_match\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            results.append({\n",
    "                \"db_id\": db_id,\n",
    "                \"question\": question,\n",
    "                \"true_query\": true_query,\n",
    "                \"llm_query\": None,\n",
    "                \"match\": False,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "results_df = run_random_tests(n=10)\n",
    "print(\"\\nSummary:\")\n",
    "print(results_df[[\"db_id\", \"match\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CITS5553-Group-9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
