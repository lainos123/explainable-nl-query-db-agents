{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f6fd853-5df0-433c-9065-0110ebcf14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f227e9-ab44-4750-9aca-f8e254a3b50c",
   "metadata": {},
   "source": [
    "<b>Schema create</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bbdd87d5-9067-4b3c-bb81-421f9c27d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, math, time, datetime, re, pathlib\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from openai import OpenAI\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict, List, Tuple\n",
    "import os, json, re\n",
    "from typing import Dict, List, Tuple\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3380753f-cef2-43da-b3eb-d00c192cbead",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA_PATH = \"tables.json\"        \n",
    "OUT_PATH = \"train_schema_embeddings.jsonl\"  \n",
    "EMBED_MODEL = \"text-embedding-3-small\"  \n",
    "CHAT_MODEL   = \"gpt-5-mini\"           \n",
    "LC_INDEX_DIR = \"faiss_idx_tables\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "13ffbb8a-5ce4-443a-ae8e-16d87c9407b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()  \n",
    "\n",
    "#open schema file\n",
    "def load_schemas(path: str) -> Dict[str, Dict[str, Any]]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        items = json.load(f)\n",
    "    return {it[\"db_id\"]: it for it in items}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f6c41494-097f-4cf0-b686-8e52885f1bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts a database schema into a compact text string by listing each table with its column names\n",
    "def schema_text(db: Dict[str, Any], max_cols_per_table: int = 24) -> str:\n",
    "    tnames = db[\"table_names_original\"]\n",
    "    cols = db[\"column_names_original\"]  \n",
    "    by_table = defaultdict(list)\n",
    "\n",
    "    for _, (tidx, cname) in enumerate(cols):\n",
    "        if tidx >= 0:  \n",
    "            by_table[tidx].append(str(cname))\n",
    "    parts = []\n",
    "    for i, t in enumerate(tnames):\n",
    "        c = by_table[i][:max_cols_per_table]\n",
    "        cols_txt = \", \".join(c)\n",
    "        parts.append(f\"{t}({cols_txt})\")\n",
    "    return \" | \".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c4972b03-b325-4b0c-b8a1-3d5e700a6389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts each schema into a readable text form mapped by its db_id\n",
    "def batch(iterable, n=64):\n",
    "    it = list(iterable)\n",
    "    for i in range(0, len(it), n):\n",
    "        yield it[i:i+n]\n",
    "def build_texts(schemas: Dict[str, Dict[str, Any]]) -> Dict[str, str]:\n",
    "    return {db_id: schema_text(db) for db_id, db in schemas.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7d3a7e67-d3ec-4bd3-88a7-b9f2a6382156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates embeddings for a list of texts by sending them to the model collecting the vector outputs, and returning them as a list of embeddings.\n",
    "def embed_texts(texts: List[str], model: str) -> List[List[float]]:\n",
    "    all_vecs = []\n",
    "    for chunk in batch(texts, n=64):\n",
    "        resp = client.embeddings.create(model=model, input=chunk)\n",
    "        all_vecs.extend([d.embedding for d in resp.data])\n",
    "        time.sleep(0.05)\n",
    "    return all_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bb562024-665a-4b6a-932d-128a8249e4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "#function loads all schemas, converts them to text, generates embeddings with the chosen model, and saves data into a JSON-lines file\n",
    "def main():\n",
    "    schemas = load_schemas(SCHEMA_PATH)\n",
    "    db_ids = list(schemas.keys())\n",
    "    db_texts = [schema_text(schemas[i]) for i in db_ids]\n",
    "\n",
    "    vecs = embed_texts(db_texts, EMBED_MODEL)\n",
    "    dims = len(vecs[0]) if vecs else 0\n",
    "    now = datetime.now(timezone.utc).isoformat().replace(\"+00:00\", \"Z\")\n",
    "\n",
    "    with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        for db_id, text, emb in zip(db_ids, db_texts, vecs):\n",
    "            rec = {\n",
    "                \"db_id\": db_id,\n",
    "                \"text\": text,\n",
    "                \"embedding\": emb,\n",
    "                \"model\": EMBED_MODEL,\n",
    "                \"dims\": dims,\n",
    "                \"updated_at\": now,\n",
    "            }\n",
    "            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "    print(\"finished\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3eb5d703-2fde-4a3e-8f4d-c8122deeaa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c0339-d464-4509-9a1a-a1ec21a7e986",
   "metadata": {},
   "source": [
    "<b>DB selector</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fc78c874-9c43-4bcf-87da-67b64a6a1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read embedding\n",
    "def load_schema_embeddings(path: str) -> List[Dict]:\n",
    "    items = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                items.append(json.loads(line))\n",
    "    for rec in items:\n",
    "        v = rec[\"embedding\"]\n",
    "        n = math.sqrt(sum(x*x for x in v)) + 1e-12\n",
    "        rec[\"_norm\"] = [x / n for x in v]\n",
    "    return items\n",
    "\n",
    "SCHEMAS = load_schema_embeddings(OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bde2457a-c95f-4499-8e43-d4f68cb1359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generates a single embedding vector for the given text\n",
    "def embed_query(text: str) -> List[float]:\n",
    "    resp = client.embeddings.create(model=EMBED_MODEL, input=[text])\n",
    "    return resp.data[0].embedding\n",
    "\n",
    "#calculates the cosine similarity between vectors\n",
    "def cosine(u: List[float], v: List[float]) -> float:\n",
    "    nu = math.sqrt(sum(x*x for x in u)) + 1e-12\n",
    "    uhat = [x/nu for x in u]\n",
    "    return sum(x*y for x, y in zip(uhat, v))\n",
    "\n",
    "#Return [(db_id, score)] highest to lowest.\n",
    "def select_db(question: str, top_k: int = 3) -> List[Tuple[str, float]]:\n",
    "    qv = embed_query(question)\n",
    "    scores = []\n",
    "    for rec in SCHEMAS:\n",
    "        score = cosine(qv, rec[\"_norm\"])\n",
    "        scores.append((rec[\"db_id\"], score))\n",
    "    scores.sort(key=lambda t: t[1], reverse=True)\n",
    "    return scores[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fb0a2d0b-0f88-4aa0-aaf9-cbf16a9c8ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top DB candidates:\n",
      "department_management  score=0.4146\n",
      "election              score=0.3079\n",
      "scientist_1           score=0.2533\n",
      "Selected: department_management\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    question = \"What are the distinct creation years of the departments managed by a secretary born in state 'Alabama'?\"\n",
    "    top = select_db(question, top_k=3)\n",
    "    print(\"Top DB candidates:\")\n",
    "    for db_id, score in top:\n",
    "        print(f\"{db_id:20s}  score={score:.4f}\")\n",
    "    topDb = top[0][0]\n",
    "    print(\"Selected:\", topDb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110bddd1-4616-4a08-9b19-6433a7c935be",
   "metadata": {},
   "source": [
    "<b>Select table</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd54f391-a919-4af4-998f-00b3a678e2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d8dcef7d-49b5-4a57-b50b-7c9fc290a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema parsing \n",
    "_TABLE_RE = re.compile(r\"\\s*([A-Za-z0-9_]+)\\s*\\(([^)]*)\\)\\s*\")\n",
    "\n",
    "def lc_load_db_records(path: str) -> List[Dict]:\n",
    "    out = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            s = line.strip()\n",
    "            if s:\n",
    "                out.append(json.loads(s))\n",
    "    return out\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7270cbd4-4cb6-4260-a9bf-1098b0e192d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert a db 'text' into per-table strings\n",
    "def lc_explode_tables(rec: Dict) -> Dict[str, str]:\n",
    "    db = rec[\"db_id\"]\n",
    "    out = {}\n",
    "    for piece in rec[\"text\"].split(\"|\"):\n",
    "        piece = piece.strip()\n",
    "        m = _TABLE_RE.match(piece)\n",
    "        if not m:\n",
    "            continue\n",
    "        tname = m.group(1)\n",
    "        cols  = \", \".join(c.strip() for c in m.group(2).split(\",\") if c.strip())\n",
    "        key = f\"{db}.{tname}\"\n",
    "        out[key] = f\"{db}.{tname}({cols})\"\n",
    "    return out\n",
    "\n",
    "def lc_build_table_texts(schema_path: str) -> Dict[str, str]:\n",
    "    tbl_texts: Dict[str, str] = {}\n",
    "    for rec in lc_load_db_records(schema_path):\n",
    "        tbl_texts.update(lc_explode_tables(rec))\n",
    "    return tbl_texts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "be45286d-4938-40d9-8ec9-fe98d9b67486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS index\n",
    "def lc_build_or_load_index(table_texts: Dict[str, str], embeddings: OpenAIEmbeddings) -> FAISS:\n",
    "    if os.path.isdir(LC_INDEX_DIR):\n",
    "        return FAISS.load_local(LC_INDEX_DIR, embeddings, allow_dangerous_deserialization=True)\n",
    "    texts = list(table_texts.values())\n",
    "    metas = [{\"table_key\": k} for k in table_texts.keys()]\n",
    "    vs = FAISS.from_texts(texts=texts, embedding=embeddings, metadatas=metas)\n",
    "    vs.save_local(LC_INDEX_DIR)\n",
    "    return vs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b6c33875-c049-4e34-bcef-9edfbfd1ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieval (with version-safe scores) \n",
    "def lc_similarity_search_tables(\n",
    "    vs: FAISS,\n",
    "    question: str,\n",
    "    table_texts: Dict[str, str],\n",
    "    k: int = 8,\n",
    "    restrict_db: str | None = None,\n",
    ") -> List[Tuple[str, float]]:\n",
    "    \"\"\"Return [(table_key, score)] where score is distance/relevance (lower usually closer).\"\"\"\n",
    "    pool_k = min(max(k * 3, 16), len(table_texts))\n",
    "    if hasattr(vs, \"similarity_search_with_score\"):\n",
    "        docs_scores = vs.similarity_search_with_score(question, k=pool_k)\n",
    "    else:\n",
    "        docs_scores = vs.similarity_search_with_relevance_scores(question, k=pool_k)\n",
    "        docs_scores = [(doc, float(score)) for doc, score in docs_scores]\n",
    "\n",
    "    if restrict_db:\n",
    "        docs_scores = [\n",
    "            (d, s) for (d, s) in docs_scores\n",
    "            if d.metadata.get(\"table_key\", \"\").split(\".\", 1)[0] == restrict_db\n",
    "        ]\n",
    "    docs_scores = docs_scores[:k]\n",
    "    return [(d.metadata[\"table_key\"], float(s)) for (d, s) in docs_scores]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fdee8be3-3a54-48b7-92ab-4069cf73a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function asks an LLM to pick the minimal set of tables needed to answer a natural-language SQL\n",
    "def lc_minimal_tables(question: str, candidates: List[str], llm: ChatOpenAI) -> List[str]:\n",
    "    sys_msg = (\n",
    "        \"You are a precise SQL planner. Given a natural-language question and a list of \"\n",
    "        \"candidate tables, return ONLY the minimal set of tables needed to answer it. \"\n",
    "        \"Prefer a single table if it contains the requested columns. Respond as strict JSON.\"\n",
    "    )\n",
    "    user_msg = (\n",
    "        f\"Question:\\n{question}\\n\\n\"\n",
    "        f\"Candidate tables:\\n\" + \"\\n\".join(f\"- {c}\" for c in candidates) + \"\\n\\n\"\n",
    "        'Return JSON exactly like: {\"tables\": [\"db.table\", \"...\"]}'\n",
    "    )\n",
    "    resp = llm.invoke([SystemMessage(content=sys_msg), HumanMessage(content=user_msg)])\n",
    "    content = resp.content or \"\"\n",
    "    try:\n",
    "        data = json.loads(content)\n",
    "    except Exception:\n",
    "        start, end = content.find(\"{\"), content.rfind(\"}\")\n",
    "        if start != -1 and end != -1 and end > start:\n",
    "            try:\n",
    "                data = json.loads(content[start:end+1])\n",
    "            except Exception:\n",
    "                return candidates[:1]\n",
    "        else:\n",
    "            return candidates[:1]\n",
    "\n",
    "    chosen = [t for t in data.get(\"tables\", []) if t in candidates]\n",
    "    return chosen or candidates[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1df95d2a-130c-4adc-9eb7-f3b277a5448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the most relevant database tables for answering a userâ€™s question\n",
    "class LCTableSelector:\n",
    "    def __init__(self, schema_jsonl: str = OUT_PATH):\n",
    "        self.table_texts = lc_build_table_texts(schema_jsonl)\n",
    "        if not self.table_texts:\n",
    "            raise RuntimeError(\"No tables parsed from schema JSONL. Check file format.\")\n",
    "        self.embeddings = OpenAIEmbeddings(model=EMBED_MODEL)\n",
    "        self.vs = lc_build_or_load_index(self.table_texts, self.embeddings)\n",
    "        self.llm = ChatOpenAI(model=CHAT_MODEL)\n",
    "\n",
    "    def select(self, question: str, db: str | None = None, k: int = 8, minimal: bool = True) -> Dict:\n",
    "        cands = lc_similarity_search_tables(self.vs, question, self.table_texts, k=k, restrict_db=db)\n",
    "        cand_keys = [t for t, _ in cands]\n",
    "        result = {\"question\": question, \"candidates\": cands}\n",
    "        result[\"selected_tables\"] = (\n",
    "            lc_minimal_tables(question, cand_keys, self.llm) if (minimal and cand_keys)\n",
    "            else (cand_keys[:1] if cand_keys else [])\n",
    "        )\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8e272230-8a41-4a17-866f-cef60ae09ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: How many rooms whose capacity is less than 50 does the Lamberton building have?\n",
      "Top candidates (lower score = closer):\n",
      "  college_2.classroom                  score=1.077\n",
      "  college_2.section                    score=1.412\n",
      "  college_2.department                 score=1.446\n",
      "Selected minimal set: ['college_2.classroom']\n"
     ]
    }
   ],
   "source": [
    "# example \n",
    "if __name__ == \"__main__\":\n",
    "    # run this file alone (do NOT import any LlamaIndex code in the same session)\n",
    "    selector = LCTableSelector(OUT_PATH)\n",
    "\n",
    "    q  = \"How many rooms whose capacity is less than 50 does the Lamberton building have?\"\n",
    "    out = selector.select(q, db=\"college_2\", k=8, minimal=True)\n",
    "\n",
    "    print(\"\\nQuestion:\", out[\"question\"])\n",
    "    print(\"Top candidates (lower score = closer):\")\n",
    "    for t, s in out[\"candidates\"]:\n",
    "        print(f\"  {t:35s}  score={s:.3f}\")\n",
    "    print(\"Selected minimal set:\", out[\"selected_tables\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2e9ce091-cb67-4ec2-8068-9ed8b130d5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  soccer_2.College                     score=1.340\n",
      "Selected minimal set: ['soccer_2.College']\n",
      "LangChain/FAISS total time: 4.78 s\n",
      "\n",
      "=== Summary ===\n",
      "LangChain/FAISS total:4.78 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "q  = \"What is the name of the school with smallest enrollment size per state\"\n",
    "db = \"soccer_2\"\n",
    "\n",
    "def run_total_time(name, selector_cls, init_args, q, db, k=8, minimal=True):\n",
    "    t_start = time.perf_counter()\n",
    "    sel = selector_cls(*init_args)                 # build\n",
    "    out = sel.select(q, db, k=k, minimal=minimal)  \n",
    "    for t, s in out[\"candidates\"]:\n",
    "        print(f\"  {t:35s}  score={s:.3f}\")\n",
    "    print(\"Selected minimal set:\", out[\"selected_tables\"])\n",
    "    \n",
    "    # query\n",
    "    total_s = time.perf_counter() - t_start\n",
    "    print(f\"{name} total time: {total_s:.2f} s\")\n",
    "    return total_s\n",
    "\n",
    "t2 = run_total_time(\"LangChain/FAISS\", LCTableSelector, (OUT_PATH,),q, db)\n",
    "\n",
    "print(\"\\n=== Summary ===\")\n",
    "print(f\"LangChain/FAISS total:{t2:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc57d598-a2d5-4b15-82ae-aa6c91145ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
