{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f197cf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.7 | Platform: Windows\n",
      "PROJECT: c:\\Users\\aswat\\OneDrive - UWA\\Desktop\\sem4\\CITS5553\\Agent_A\n",
      "DATA_DIR: c:\\Users\\aswat\\OneDrive - UWA\\Desktop\\sem4\\CITS5553\\Agent_A\\spider_data\\spider_data\n",
      "tables.json          exists? True  -> c:\\Users\\aswat\\OneDrive - UWA\\Desktop\\sem4\\CITS5553\\Agent_A\\spider_data\\spider_data\\tables.json\n",
      "train_spider.json    exists? True  -> c:\\Users\\aswat\\OneDrive - UWA\\Desktop\\sem4\\CITS5553\\Agent_A\\spider_data\\spider_data\\train_spider.json\n",
      "dev.json             exists? True  -> c:\\Users\\aswat\\OneDrive - UWA\\Desktop\\sem4\\CITS5553\\Agent_A\\spider_data\\spider_data\\dev.json\n",
      "database             exists? True  -> c:\\Users\\aswat\\OneDrive - UWA\\Desktop\\sem4\\CITS5553\\Agent_A\\spider_data\\spider_data\\database\n"
     ]
    }
   ],
   "source": [
    "# Setup & sanity checks\n",
    "from pathlib import Path\n",
    "import sys, platform\n",
    "\n",
    "# Project root is wherever this notebook lives (Agent_A/)\n",
    "PROJECT = Path.cwd()\n",
    "\n",
    "# Handle both common Spider layouts:\n",
    "# 1) Agent_A/spider_data/\n",
    "# 2) Agent_A/spider_data/spider_data/\n",
    "if (PROJECT / \"spider_data\" / \"spider_data\").exists():\n",
    "    DATA_DIR = PROJECT / \"spider_data\" / \"spider_data\"\n",
    "else:\n",
    "    DATA_DIR = PROJECT / \"spider_data\"\n",
    "\n",
    "# Key Spider files\n",
    "TABLES_JSON = DATA_DIR / \"tables.json\"\n",
    "TRAIN_JSON  = DATA_DIR / \"train_spider.json\"\n",
    "DEV_JSON    = DATA_DIR / \"dev.json\"\n",
    "DB_ROOT     = DATA_DIR / \"database\"  # folder with sqlite DBs (not needed yet, but good to verify)\n",
    "\n",
    "# Where we’ll store intermediate artifacts\n",
    "OUTPUT_DIR = PROJECT / \"output\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0], \"| Platform:\", platform.system())\n",
    "print(\"PROJECT:\", PROJECT)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "\n",
    "for p in [TABLES_JSON, TRAIN_JSON, DEV_JSON, DB_ROOT]:\n",
    "    print(f\"{p.name:<20} exists? {p.exists()}  -> {p}\")\n",
    "\n",
    "# Hard requirement for next steps (building schema cards)\n",
    "assert TABLES_JSON.exists(), (\n",
    "    \"tables.json not found.\\n\"\n",
    "    \"Fix DATA_DIR or move your Spider data into Agent_A/spider_data/ \"\n",
    "    \"(or Agent_A/spider_data/spider_data/).\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "970625ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "NumPy: 2.3.2 | scikit-learn: 1.7.1\n",
      "Python executable: c:\\Users\\aswat\\OneDrive - UWA\\Desktop\\sem4\\CITS5553\\Agent_A\\agent\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "%pip install -q --upgrade pip\n",
    "%pip install -q numpy scikit-learn\n",
    "%pip install -q sentence-transformers\n",
    "%pip install -q openai\n",
    "\n",
    "import numpy, sklearn, sys\n",
    "print(\"NumPy:\", numpy.__version__, \"| scikit-learn:\", sklearn.__version__)\n",
    "print(\"Python executable:\", sys.executable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "231325e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: C:\\Users\\aswat\\OneDrive - UWA\\Desktop\\sem4\\CITS5553\\Agent_A\\agent_a_core.py\n",
      "Imported agent_a_core  Backend: OpenAIBackend\n"
     ]
    }
   ],
   "source": [
    "# Create agent_a_core.py (OpenAI embeddings only) and import it\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "module_code = r'''\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from pathlib import Path\n",
    "import json, os\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------\n",
    "# OpenAI Embedding backend only\n",
    "# ------------------------------\n",
    "\n",
    "class OpenAIBackend:\n",
    "    \"\"\"\n",
    "    OpenAI embeddings backend.\n",
    "    - Default model: text-embedding-3-small\n",
    "    - Expects OPENAI_API_KEY in environment.\n",
    "    \"\"\"\n",
    "    name: str = \"openai\"\n",
    "    dim: Optional[int] = None\n",
    "\n",
    "    def __init__(self, model: str = \"text-embedding-3-small\", batch_size: int = 128):\n",
    "        try:\n",
    "            from openai import OpenAI  # type: ignore\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"OpenAI SDK not available. Install 'openai' (>= 1.0).\") from e\n",
    "        if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "            raise RuntimeError(\"OPENAI_API_KEY not set in environment.\")\n",
    "        self.client = OpenAI()\n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def encode(self, texts: List[str]) -> np.ndarray:\n",
    "        out = []\n",
    "        bs = self.batch_size\n",
    "        for i in range(0, len(texts), bs):\n",
    "            chunk = texts[i:i+bs]\n",
    "            resp = self.client.embeddings.create(model=self.model, input=chunk)\n",
    "            vecs = [np.asarray(d.embedding, dtype=\"float32\") for d in resp.data]\n",
    "            out.append(np.vstack(vecs))\n",
    "        arr = np.vstack(out) if out else np.zeros((0, 1536), dtype=\"float32\")\n",
    "        # Normalize for cosine similarity with inner product\n",
    "        norms = np.linalg.norm(arr, axis=1, keepdims=True) + 1e-12\n",
    "        arr = arr / norms\n",
    "        return arr\n",
    "\n",
    "    def encode_one(self, text: str) -> np.ndarray:\n",
    "        return self.encode([text])[0:1]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Schema cards from Spider tables.json (unchanged)\n",
    "# ------------------------------\n",
    "\n",
    "def build_schema_cards(tables_json_path: Path, max_cols_per_table: int = 12) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Read Spider tables.json and produce a compact text summary per DB:\n",
    "      return { 'db_ids': [...], 'cards': [...] }\n",
    "    Each 'card' is multiline text that lists tables, columns(types),\n",
    "    and foreign key hints to boost semantic matching.\n",
    "    \"\"\"\n",
    "    raw = json.loads(tables_json_path.read_text(encoding=\"utf-8\"))\n",
    "    tables_all = raw[\"db\"] if isinstance(raw, dict) and \"db\" in raw else raw\n",
    "\n",
    "    db_ids: List[str] = []\n",
    "    cards: List[str] = []\n",
    "\n",
    "    for db in tables_all:\n",
    "        db_id = db[\"db_id\"]\n",
    "        tnames = db.get(\"table_names_original\") or db.get(\"table_names\", [])\n",
    "        columns = db.get(\"column_names_original\") or db.get(\"column_names\", [])  # [[table_id, col], ...]\n",
    "        ctypes = db.get(\"column_types\", [])\n",
    "        fks = db.get(\"foreign_keys\", [])  # pairs of column indices\n",
    "\n",
    "        # table -> [(col_name, col_type), ...]\n",
    "        by_table: Dict[str, List[Tuple[str,str]]] = {}\n",
    "        for idx, (tid, col) in enumerate(columns):\n",
    "            if tid >= 0:\n",
    "                tname = tnames[tid]\n",
    "                by_table.setdefault(tname, []).append((col, ctypes[idx] if idx < len(ctypes) else \"text\"))\n",
    "\n",
    "        lines = [f\"[DB:{db_id}]\"]\n",
    "        for t in tnames:\n",
    "            cols = \", \".join([f\"{c}({ct})\" for c, ct in (by_table.get(t, [])[:max_cols_per_table])])\n",
    "            lines.append(f\"- {t}: {cols}\")\n",
    "\n",
    "        if fks:\n",
    "            # add FK hints\n",
    "            def col_name(ci):\n",
    "                if 0 <= ci < len(columns):\n",
    "                    tid, col = columns[ci]\n",
    "                    if tid >= 0:\n",
    "                        return f\"{tnames[tid]}.{col}\"\n",
    "                return f\"col{ci}\"\n",
    "            fk_pairs = [f\"{col_name(a)} -> {col_name(b)}\" for a, b in fks]\n",
    "            lines.append(\"ForeignKeys: \" + \"; \".join(fk_pairs))\n",
    "\n",
    "        cards.append(\"\\\\n\".join(lines))\n",
    "        db_ids.append(db_id)\n",
    "\n",
    "    return {\"db_ids\": db_ids, \"cards\": cards}\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Agent A: propose & auto_select\n",
    "# (OpenAI embeddings)\n",
    "# ------------------------------\n",
    "\n",
    "@dataclass\n",
    "class Candidate:\n",
    "    db_id: str\n",
    "    score: float\n",
    "\n",
    "class AgentA:\n",
    "    \"\"\"\n",
    "    Minimal Agent for DB selection:\n",
    "      - Embeds DB cards once using OpenAI embeddings.\n",
    "      - For a question, embeds the query and returns top-K DB candidates by cosine similarity.\n",
    "      - auto_select() chooses the top-1 by similarity among provided candidates.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 db_cards: List[str],\n",
    "                 db_ids: List[str],\n",
    "                 embedder: Optional[OpenAIBackend] = None):\n",
    "        assert len(db_cards) == len(db_ids), \"db_cards and db_ids must align\"\n",
    "        self.db_cards = db_cards\n",
    "        self.db_ids = db_ids\n",
    "        self.embedder = embedder or OpenAIBackend()\n",
    "\n",
    "        # Precompute DB vectors\n",
    "        self.X_db = self.embedder.encode(self.db_cards)\n",
    "\n",
    "    def _topk_from_matrix(self, M: np.ndarray, q_vec: np.ndarray, k: int):\n",
    "        # cosine == dot for L2-normalized vectors\n",
    "        sims = (M @ q_vec.T).ravel()\n",
    "        idx = np.argsort(-sims)[:k]\n",
    "        return sims[idx], idx\n",
    "\n",
    "    def propose(self, question: str, top: int = 3, pool: int = 20) -> Dict[str, Any]:\n",
    "        q_vec = self.embedder.encode_one(question)\n",
    "        sims_db, idx_db = self._topk_from_matrix(self.X_db, q_vec, k=min(pool, len(self.db_ids)))\n",
    "\n",
    "        cands: List[Candidate] = []\n",
    "        used = set()\n",
    "        for score, idx in zip(sims_db, idx_db):\n",
    "            db_id = self.db_ids[int(idx)]\n",
    "            if db_id in used:\n",
    "                continue\n",
    "            cands.append(Candidate(db_id=db_id, score=float(score)))\n",
    "            used.add(db_id)\n",
    "            if len(cands) == top:\n",
    "                break\n",
    "\n",
    "        return {\n",
    "            \"query\": question,\n",
    "            \"candidates\": [c.__dict__ for c in cands],\n",
    "            \"instruction\": \"Reply with the db_id to use. If unsure, reply 'auto'.\"\n",
    "        }\n",
    "\n",
    "    def auto_select(self, question: str, candidates: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Pick the best candidate purely by query→DB-card similarity.\n",
    "        \"\"\"\n",
    "        if not candidates:\n",
    "            raise ValueError(\"No candidates provided to auto_select().\")\n",
    "        q_vec = self.embedder.encode_one(question)\n",
    "\n",
    "        # Build mask for candidate ids\n",
    "        cand_ids = [c[\"db_id\"] for c in candidates]\n",
    "        id_to_idx = {db_id: i for i, db_id in enumerate(self.db_ids)}\n",
    "\n",
    "        # Compute similarity only over candidate set\n",
    "        sims = []\n",
    "        for db_id in cand_ids:\n",
    "            j = id_to_idx.get(db_id)\n",
    "            if j is None:\n",
    "                continue\n",
    "            s = float((self.X_db[j:j+1] @ q_vec.T).ravel()[0])\n",
    "            sims.append((db_id, s))\n",
    "\n",
    "        if not sims:\n",
    "            # Fallback: first provided candidate\n",
    "            return {\"selected_db_id\": candidates[0][\"db_id\"], \"reason\": \"fallback: first candidate (no sims)\"}\n",
    "\n",
    "        sims.sort(key=lambda x: -x[1])\n",
    "        best_id, best_s = sims[0]\n",
    "        return {\"selected_db_id\": best_id, \"reason\": f\"highest DB-card similarity {best_s:.4f} among candidates\"}\n",
    "'''\n",
    "\n",
    "# write the module\n",
    "path = Path(\"agent_a_core.py\")\n",
    "path.write_text(module_code, encoding=\"utf-8\")\n",
    "print(\"Wrote:\", path.resolve())\n",
    "\n",
    "# import to verify\n",
    "import agent_a_core\n",
    "importlib.reload(agent_a_core)\n",
    "print(\"Imported agent_a_core  Backend:\", getattr(agent_a_core, \"OpenAIBackend\").__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f96df54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built schema cards for 166 databases\n",
      "Saved to: c:\\Users\\aswat\\OneDrive - UWA\\Desktop\\sem4\\CITS5553\\Agent_A\\output\\db_cards.json\n",
      "\n",
      "--- Card 0 for DB: perpetrator ---\n",
      "[DB:perpetrator]\\n- perpetrator: Perpetrator_ID(number), People_ID(number), Date(text), Year(number), Location(text), Country(text), Killed(number), Injured(number)\\n- people: People_ID(number), Name(text), Height(number), Weight(number), Home Town(text)\\nForeignKeys: perpetrator.People_ID -> people.People_ID\n",
      "\n",
      "--- Card 1 for DB: college_2 ---\n",
      "[DB:college_2]\\n- classroom: building(text), room_number(text), capacity(number)\\n- department: dept_name(text), building(text), budget(number)\\n- course: course_id(text), title(text), dept_name(text), credits(number)\\n- instructor: ID(text), name(text), dept_name(text), salary(number)\\n- section: course_id(text), sec_id(text), semester(text), year(number), building(text), room_number(text), time_slot_id(text)\\n- teaches: ID(text), course_id(text), sec_id(text), semester(text), year(number)\\n- student: ID(text), name(text), dept_name(text), tot_cred(number)\\n- takes: ID(text), course_id(text), sec_id(text), semester(text), year(number), grade(text)\\n- advisor: s_ID(text), i_ID(text)\\n- time_slot: time_slot_id(text), day(text), start_hr(number), start_min(number), end_hr(number), end_min(nu...\n"
     ]
    }
   ],
   "source": [
    "# Build schema cards from Spider tables.json\n",
    "import json\n",
    "from agent_a_core import build_schema_cards\n",
    "\n",
    "# Build cards (uses tables.json from Cell 1)\n",
    "cards_meta = build_schema_cards(TABLES_JSON, max_cols_per_table=100)\n",
    "db_ids, cards = cards_meta[\"db_ids\"], cards_meta[\"cards\"]\n",
    "\n",
    "# Basic sanity checks\n",
    "assert len(db_ids) == len(cards), \"Mismatch: db_ids and cards should be aligned\"\n",
    "assert len(set(db_ids)) == len(db_ids), \"Duplicate db_ids found — check your tables.json\"\n",
    "\n",
    "# Persist for reuse\n",
    "out_path = OUTPUT_DIR / \"db_cards.json\"\n",
    "out_path.write_text(json.dumps(cards_meta, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Built schema cards for {len(db_ids)} databases\")\n",
    "print(f\"Saved to: {out_path}\")\n",
    "\n",
    "# Preview a couple of cards (trimmed)\n",
    "for i in range(min(2, len(cards))):\n",
    "    print(\"\\n--- Card\", i, \"for DB:\", db_ids[i], \"---\")\n",
    "    preview = cards[i]\n",
    "    print(preview[:800] + (\"...\" if len(preview) > 800 else \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0376e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has OPENAI_API_KEY: True\n",
      "OpenAI SDK import OK\n"
     ]
    }
   ],
   "source": [
    "# SDK + key\n",
    "import os\n",
    "print(\"Has OPENAI_API_KEY:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    _ = OpenAI()\n",
    "    print(\"OpenAI SDK import OK\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"OpenAI SDK missing/outdated. Run: %pip install -q openai\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1438b4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OpenAI text-embedding-3-large] Agent ready. DBs: 166 | Init: 7.11s\n"
     ]
    }
   ],
   "source": [
    "# OpenAI embedder on DB cards (no QAs)\n",
    "from time import time\n",
    "from agent_a_core import OpenAIBackend, AgentA\n",
    "\n",
    "OPENAI_MODEL = \"text-embedding-3-large\"   # or \"text-embedding-3-small\" (cheaper)\n",
    "USE_QA = False  # keep cost low: only cards\n",
    "\n",
    "embedder_openai = OpenAIBackend(model=OPENAI_MODEL)\n",
    "\n",
    "t0 = time()\n",
    "agent_openai = AgentA(\n",
    "    db_cards=cards,\n",
    "    db_ids=db_ids,\n",
    "    embedder=embedder_openai\n",
    ")\n",
    "print(f\"[OpenAI {OPENAI_MODEL}] Agent ready. DBs: {len(db_ids)} | Init: {time()-t0:.2f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b8d2cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple & efficient LLM reranker (cards-only is fine)\n",
    "from openai import OpenAI\n",
    "import json, re\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def llm_pick_best_db(\n",
    "    query: str,\n",
    "    candidates: list,\n",
    "    cards: list,\n",
    "    db_ids: list,\n",
    "    model: str = \"gpt-4o-mini\",\n",
    "    max_schema_chars: int = 900,      # keep tokens low\n",
    "    max_schema_lines: int = 12,       # or trim by lines\n",
    "    max_keywords: int = 20            # from \"Tags:\" line if present\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    candidates: agent.propose(...)[\\\"candidates\\\"]\n",
    "    returns: { \"best_db_id\": \"...\", \"reason\": \"...\" }\n",
    "    \"\"\"\n",
    "\n",
    "    if not candidates:\n",
    "        raise ValueError(\"llm_pick_best_db: no candidates provided\")\n",
    "\n",
    "    # Build compact candidate blocks: db_id + (optional) Keywords + trimmed Schema\n",
    "    blocks = []\n",
    "    valid_ids = []\n",
    "    for i, c in enumerate(candidates, 1):\n",
    "        db = c[\"db_id\"]\n",
    "        valid_ids.append(db)\n",
    "        card = cards[db_ids.index(db)] if db in db_ids else \"\"\n",
    "\n",
    "        # pull Keywords from a \"Tags:\" line if present\n",
    "        m = re.search(r\"(?mi)^Tags:\\s*(.*)$\", card)\n",
    "        keywords = [t.strip() for t in m.group(1).split(\",\")] if m else []\n",
    "        keywords = \", \".join(keywords[:max_keywords]) if keywords else \"(none)\"\n",
    "\n",
    "        # trim schema by lines then chars\n",
    "        lines = [ln for ln in card.split(\"\\n\") if ln.strip()]\n",
    "        schema = \"\\n\".join(lines[:max_schema_lines])[:max_schema_chars]\n",
    "\n",
    "        blocks.append(f\"{i}) db_id={db}\\nKeywords: {keywords}\\nSchema:\\n{schema}\")\n",
    "\n",
    "    system = (\n",
    "        \"You are a strict database router. Choose EXACTLY one db_id from the candidates.\\n\"\n",
    "        \"Decision rules:\\n\"\n",
    "        \"1) Prefer schemas whose COLUMN/TABLE NAMES or Keywords literally match the user's terms.\\n\"\n",
    "        \"2) Ensure required relations/joins exist for the question.\\n\"\n",
    "        \"3) Break ties by the most specific coverage. Do not invent db_ids.\\n\"\n",
    "        'Return strict JSON: {\"best_db_id\": \"...\", \"reason\": \"...\"} with reason ≤ 25 words.'\n",
    "    )\n",
    "\n",
    "    user = (\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        \"Candidates:\\n\" + \"\\n\\n\".join(blocks) + \"\\n\\n\"\n",
    "        \"Pick the single best db_id.\"\n",
    "    )\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"system\", \"content\": system},\n",
    "                  {\"role\": \"user\", \"content\": user}],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # Parse + validate\n",
    "    try:\n",
    "        data = json.loads(resp.choices[0].message.content)\n",
    "    except Exception:\n",
    "        # fallback: pick top-1 candidate\n",
    "        return {\"best_db_id\": candidates[0][\"db_id\"], \"reason\": \"fallback: invalid JSON from model\"}\n",
    "\n",
    "    if data.get(\"best_db_id\") not in set(valid_ids):\n",
    "        # guardrail: ensure selection is one of the candidates\n",
    "        return {\"best_db_id\": candidates[0][\"db_id\"], \"reason\": \"fallback: invalid db_id from model\"}\n",
    "\n",
    "    # optionally clip reason\n",
    "    reason = str(data.get(\"reason\", \"\"))[:150]\n",
    "    return {\"best_db_id\": data[\"best_db_id\"], \"reason\": reason}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42c5b060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specific test questions + expected db_id\n",
    "tests = [\n",
    "     (\"List each customer’s total checking+saving balance and return the top 5.\", \"small_bank_1\"),\n",
    "    (\"Which customer has the highest savings balance and what is their checking balance?\", \"small_bank_1\"),\n",
    "    (\"Show customers and total transaction count per card, highest first.\", \"customers_card_transactions\"),\n",
    "\n",
    "    # music\n",
    "    (\"Albums released after 2015 with their label and type.\", \"music_2\"),\n",
    "    (\"Songs with rating >= 9 and their genres and artists.\", \"music_1\"),\n",
    "    (\"Artists whose songs had Weeks_on_Top >= 8 along with Issue_Date.\", \"music_4\"),\n",
    "\n",
    "    # education / university\n",
    "    (\"Instructors with salary > 100000 and their department names.\", \"college_2\"),\n",
    "    (\"Courses with >=4 credits and the number of sections offered per year.\", \"college_2\"),\n",
    "    (\"Students and their total credits (tot_cred), descending.\", \"college_2\"),\n",
    "\n",
    "    # flights (note: different schemas!)\n",
    "    (\"Flights with origin 'Dallas' and destination 'Seattle' in year 2017.\", \"flight_1\"),\n",
    "    (\"List routes with codeshare='Y' and show airline callsign.\", \"flight_4\"),\n",
    "    (\"Flights from AirportCode 'DFW' to 'LAX' with airline name.\", \"flight_2\"),\n",
    "    (\"For each operate_company, count total flights operated with average altitude.\", \"flight_company\"),\n",
    "\n",
    "    # people / sport / competition\n",
    "    (\"Body builder with the highest Total and their Birth_Place.\", \"body_builder\"),\n",
    "    (\"Races held at tracks with Seating > 50000 and the track location.\", \"race_track\"),\n",
    "    (\"Clubs with the most Gold medals and their Total medals.\", \"sports_competition\"),\n",
    "\n",
    "    # authors / papers / academic\n",
    "    (\"Papers written by author last name 'Smith' and their institutions.\", \"icfp_1\"),\n",
    "    (\"For each domain, count publications after year 2010, highest first.\", \"academic\"),\n",
    "    (\"Top 5 keywords by number of publications.\", \"academic\"),\n",
    "\n",
    "    # weather / cities / events\n",
    "    (\"For each city, list GDP and Regional_Population sorted by GDP desc.\", \"city_record\"),\n",
    "    (\"Average July temperature for cities that hosted at least one match.\", \"city_record\"),\n",
    "    (\"Stations with wind_speed_mph > 20 on 'Monday' and the trains that stop there.\", \"station_weather\"),\n",
    "\n",
    "    # government / elections\n",
    "    (\"Election rows for County_name 'Montgomery' including its District.\", \"election\"),\n",
    "    (\"Count of events per Service_Type_Code in Alabama local government.\", \"local_govt_in_alabama\"),\n",
    "\n",
    "    # health / medicine\n",
    "    (\"Medicines that interact with enzyme 'CYP3A4'.\", \"medicine_enzyme_interaction\"),\n",
    "    (\"Customers with an available policy and settlement amounts paid to them.\", \"insurance_fnol\"),\n",
    "\n",
    "    # retail / orders\n",
    "    (\"For each customer, compute total order value and sort descending.\", \"department_store\"),\n",
    "    (\"Total value purchased per supplier (Product_Suppliers.total_value_purchased).\", \"department_store\"),\n",
    "    (\"Stores that sell products with dpi > 600 and their product count.\", \"store_product\"),\n",
    "    (\"Members with Level >= 3 and total pounds spent per branch.\", \"shop_membership\"),\n",
    "\n",
    "    # logistics / devices / markets\n",
    "    (\"Phones with Memory_in_G >= 128 and total stock across all markets.\", \"phone_market\"),\n",
    "    (\"Total stock per carrier across all markets, descending.\", \"phone_market\"),\n",
    "\n",
    "    # maintenance / assets\n",
    "    (\"Engineers with a given skill who visited any asset under maintenance contract.\", \"assets_maintenance\"),\n",
    "    (\"Assets and number of recorded faults, highest first.\", \"assets_maintenance\"),\n",
    "\n",
    "    # students / courses / assessments\n",
    "    (\"Students registered for a course but with no attendance records.\", \"student_assessment\"),\n",
    "    (\"Candidates with PASS assessment outcome and their qualification.\", \"student_assessment\"),\n",
    "\n",
    "    # animals / clinics\n",
    "    (\"Total treatment cost per dog and the owner's full name.\", \"dog_kennels\"),\n",
    "    (\"Number of treatments per breed and average treatment cost.\", \"dog_kennels\"),\n",
    "\n",
    "    # employment / companies\n",
    "    (\"People employed at any company in the year 2010 and the company name.\", \"company_employee\"),\n",
    "\n",
    "    # agriculture / farm\n",
    "    (\"Farm with the highest Total_Cattle in the most recent year.\", \"farm\"),\n",
    "    (\"For each farm, list Year and total pigs and cows combined.\", \"farm\"),\n",
    "\n",
    "    # solvency / events (regulatory)\n",
    "    (\"Count events per Channel_ID and list the top 5.\", \"solvency_ii\"),\n",
    "    (\"Assets involved in events and the related Locations.\", \"solvency_ii\"),\n",
    "\n",
    "    # misc domains\n",
    "    (\"Swimmer with the best Time and the city of the stadium where they competed.\", \"swimming\"),\n",
    "    (\"Debates with Num_of_Audience > 1000 and the age of the affirmative debater.\", \"debate\"),\n",
    "    (\"List friends of 'Alice' in the year 2015.\", \"network_2\"),\n",
    "    (\"Students living in dorms with the amenity 'Gym'.\", \"dorm_1\"),\n",
    "    (\"Editors older than 50 serving on any journal committee and the journal theme.\", \"journal_committee\"),\n",
    "    (\"Captains and their ship names for ships built before 1950.\", \"ship_1\"),\n",
    "    (\"Artworks that won at a festival and the festival year.\", \"entertainment_awards\"),\n",
    "    (\"Students who have the allergy type 'Peanut'.\", \"allergy_1\"),\n",
    "    (\"Students who own a pet of type 'Cat'.\", \"pets_1\"),\n",
    "    (\"Bookings returned_late_yn = 'Y' and the customer full names.\", \"products_for_hire\"),\n",
    "    (\"Candidates and their support rates grouped by Poll_Source.\", \"candidate_poll\"),\n",
    "    (\"Top 5 customers by total invoice amount in Chinook.\", \"chinook_1\"),\n",
    "    (\"Browsers compatible since year >= 2015 for accelerator named 'SpeedX'.\", \"browser_web\"),\n",
    "    (\"Trains on railway named 'Trans-Australia' and the manager responsible.\", \"railway\"),\n",
    "    (\"Rooms with maxOccupancy > 4 and total reserved nights.\", \"inn_1\"),\n",
    "    (\"Visitors who spent more than 100 at any museum and the museum name.\", \"museum_visit\"),\n",
    "    (\"Courses under subject 'Math' and enrolled student counts.\", \"e_learning\"),\n",
    "]\n",
    "len(tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf9d2690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 54 / 60 = 0.900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>expected_db</th>\n",
       "      <th>picked_db</th>\n",
       "      <th>correct</th>\n",
       "      <th>candidates</th>\n",
       "      <th>llm_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Instructors with salary &gt; 100000 and their dep...</td>\n",
       "      <td>college_2</td>\n",
       "      <td>college_1</td>\n",
       "      <td>False</td>\n",
       "      <td>[department_management, college_1, student_1]</td>\n",
       "      <td>It includes EMPLOYEE and DEPARTMENT tables, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Students and their total credits (tot_cred), d...</td>\n",
       "      <td>college_2</td>\n",
       "      <td>college_1</td>\n",
       "      <td>False</td>\n",
       "      <td>[student_transcripts_tracking, college_1, stud...</td>\n",
       "      <td>Contains 'STUDENT' and 'STU_HRS' for total cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For each customer, compute total order value a...</td>\n",
       "      <td>department_store</td>\n",
       "      <td>tracking_orders</td>\n",
       "      <td>False</td>\n",
       "      <td>[tracking_orders, customers_and_invoices, cust...</td>\n",
       "      <td>It includes Orders and Customers, allowing for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Total value purchased per supplier (Product_Su...</td>\n",
       "      <td>department_store</td>\n",
       "      <td>products_gen_characteristics</td>\n",
       "      <td>False</td>\n",
       "      <td>[products_gen_characteristics, manufactory_1, ...</td>\n",
       "      <td>No other candidate has a relevant schema for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Students registered for a course but with no a...</td>\n",
       "      <td>student_assessment</td>\n",
       "      <td>e_learning</td>\n",
       "      <td>False</td>\n",
       "      <td>[e_learning, student_assessment, student_trans...</td>\n",
       "      <td>It includes Students and Student_Course_Enrolm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Count events per Channel_ID and list the top 5.</td>\n",
       "      <td>solvency_ii</td>\n",
       "      <td>program_share</td>\n",
       "      <td>False</td>\n",
       "      <td>[program_share, tvshow, news_report]</td>\n",
       "      <td>Contains Channel_ID and relevant broadcast tab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>List each customer’s total checking+saving bal...</td>\n",
       "      <td>small_bank_1</td>\n",
       "      <td>small_bank_1</td>\n",
       "      <td>True</td>\n",
       "      <td>[small_bank_1, loan_1, customers_card_transact...</td>\n",
       "      <td>It has the required accounts and balances for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Which customer has the highest savings balance...</td>\n",
       "      <td>small_bank_1</td>\n",
       "      <td>small_bank_1</td>\n",
       "      <td>True</td>\n",
       "      <td>[small_bank_1, loan_1, customers_card_transact...</td>\n",
       "      <td>It contains savings and checking balances link...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Show customers and total transaction count per...</td>\n",
       "      <td>customers_card_transactions</td>\n",
       "      <td>customers_card_transactions</td>\n",
       "      <td>True</td>\n",
       "      <td>[customers_card_transactions, customers_and_in...</td>\n",
       "      <td>It contains relevant tables for customers and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Albums released after 2015 with their label an...</td>\n",
       "      <td>music_2</td>\n",
       "      <td>music_2</td>\n",
       "      <td>True</td>\n",
       "      <td>[music_2, music_4, music_1]</td>\n",
       "      <td>Contains Albums with Year, Label, and Type mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Songs with rating &gt;= 9 and their genres and ar...</td>\n",
       "      <td>music_1</td>\n",
       "      <td>music_1</td>\n",
       "      <td>True</td>\n",
       "      <td>[music_1, music_4, music_2]</td>\n",
       "      <td>It includes songs with ratings, genres, and ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Artists whose songs had Weeks_on_Top &gt;= 8 alon...</td>\n",
       "      <td>music_4</td>\n",
       "      <td>music_4</td>\n",
       "      <td>True</td>\n",
       "      <td>[music_4, singer, music_1]</td>\n",
       "      <td>Schema includes Weeks_on_Top and Issue_Date, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Courses with &gt;=4 credits and the number of sec...</td>\n",
       "      <td>college_2</td>\n",
       "      <td>college_2</td>\n",
       "      <td>True</td>\n",
       "      <td>[college_1, student_transcripts_tracking, coll...</td>\n",
       "      <td>Schema includes 'course' with credits and 'sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Flights with origin 'Dallas' and destination '...</td>\n",
       "      <td>flight_1</td>\n",
       "      <td>flight_1</td>\n",
       "      <td>True</td>\n",
       "      <td>[flight_4, flight_2, flight_1]</td>\n",
       "      <td>Schema includes 'origin' and 'destination' mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>List routes with codeshare='Y' and show airlin...</td>\n",
       "      <td>flight_4</td>\n",
       "      <td>flight_4</td>\n",
       "      <td>True</td>\n",
       "      <td>[flight_4, flight_2, program_share]</td>\n",
       "      <td>Schema includes routes with codeshare and airl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Flights from AirportCode 'DFW' to 'LAX' with a...</td>\n",
       "      <td>flight_2</td>\n",
       "      <td>flight_2</td>\n",
       "      <td>True</td>\n",
       "      <td>[flight_2, flight_4, flight_company]</td>\n",
       "      <td>It directly includes flights, airports, and ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>For each operate_company, count total flights ...</td>\n",
       "      <td>flight_company</td>\n",
       "      <td>flight_company</td>\n",
       "      <td>True</td>\n",
       "      <td>[flight_company, flight_1, flight_2]</td>\n",
       "      <td>It contains operate_company and flight tables ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Body builder with the highest Total and their ...</td>\n",
       "      <td>body_builder</td>\n",
       "      <td>body_builder</td>\n",
       "      <td>True</td>\n",
       "      <td>[body_builder, gymnast, poker_player]</td>\n",
       "      <td>Schema includes Total and Birth_Place, matchin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Races held at tracks with Seating &gt; 50000 and ...</td>\n",
       "      <td>race_track</td>\n",
       "      <td>race_track</td>\n",
       "      <td>True</td>\n",
       "      <td>[race_track, formula_1, farm]</td>\n",
       "      <td>It includes track seating and location, direct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Clubs with the most Gold medals and their Tota...</td>\n",
       "      <td>sports_competition</td>\n",
       "      <td>sports_competition</td>\n",
       "      <td>True</td>\n",
       "      <td>[sports_competition, riding_club, swimming]</td>\n",
       "      <td>It contains Gold and Total medal counts with n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Papers written by author last name 'Smith' and...</td>\n",
       "      <td>icfp_1</td>\n",
       "      <td>icfp_1</td>\n",
       "      <td>True</td>\n",
       "      <td>[icfp_1, academic, scholar]</td>\n",
       "      <td>Schema includes Authors and Papers with necess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>For each domain, count publications after year...</td>\n",
       "      <td>academic</td>\n",
       "      <td>academic</td>\n",
       "      <td>True</td>\n",
       "      <td>[academic, book_2, icfp_1]</td>\n",
       "      <td>Schema includes publications and domains, allo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Top 5 keywords by number of publications.</td>\n",
       "      <td>academic</td>\n",
       "      <td>academic</td>\n",
       "      <td>True</td>\n",
       "      <td>[academic, scholar, icfp_1]</td>\n",
       "      <td>Contains 'keyword' and 'publication' tables ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>For each city, list GDP and Regional_Populatio...</td>\n",
       "      <td>city_record</td>\n",
       "      <td>city_record</td>\n",
       "      <td>True</td>\n",
       "      <td>[world_1, city_record, geo]</td>\n",
       "      <td>It contains GDP and Regional_Population with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Average July temperature for cities that hoste...</td>\n",
       "      <td>city_record</td>\n",
       "      <td>city_record</td>\n",
       "      <td>True</td>\n",
       "      <td>[city_record, farm, soccer_1]</td>\n",
       "      <td>It contains temperature data and match hosting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Stations with wind_speed_mph &gt; 20 on 'Monday' ...</td>\n",
       "      <td>station_weather</td>\n",
       "      <td>station_weather</td>\n",
       "      <td>True</td>\n",
       "      <td>[station_weather, train_station, bike_1]</td>\n",
       "      <td>It includes wind_speed_mph and necessary relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Election rows for County_name 'Montgomery' inc...</td>\n",
       "      <td>election</td>\n",
       "      <td>election</td>\n",
       "      <td>True</td>\n",
       "      <td>[election, election_representative, county_pub...</td>\n",
       "      <td>Schema includes County_name and District, matc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Count of events per Service_Type_Code in Alaba...</td>\n",
       "      <td>local_govt_in_alabama</td>\n",
       "      <td>local_govt_in_alabama</td>\n",
       "      <td>True</td>\n",
       "      <td>[local_govt_in_alabama, local_govt_and_lot, co...</td>\n",
       "      <td>It contains Service_Type_Code and Events, allo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Medicines that interact with enzyme 'CYP3A4'.</td>\n",
       "      <td>medicine_enzyme_interaction</td>\n",
       "      <td>medicine_enzyme_interaction</td>\n",
       "      <td>True</td>\n",
       "      <td>[medicine_enzyme_interaction, hospital_1, cust...</td>\n",
       "      <td>Schema includes enzyme interactions, directly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Customers with an available policy and settlem...</td>\n",
       "      <td>insurance_fnol</td>\n",
       "      <td>insurance_fnol</td>\n",
       "      <td>True</td>\n",
       "      <td>[insurance_fnol, insurance_policies, insurance...</td>\n",
       "      <td>It includes policies and settlements, directly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Stores that sell products with dpi &gt; 600 and t...</td>\n",
       "      <td>store_product</td>\n",
       "      <td>store_product</td>\n",
       "      <td>True</td>\n",
       "      <td>[store_product, product_catalog, products_gen_...</td>\n",
       "      <td>It contains 'dpi' and relates stores to produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Members with Level &gt;= 3 and total pounds spent...</td>\n",
       "      <td>shop_membership</td>\n",
       "      <td>shop_membership</td>\n",
       "      <td>True</td>\n",
       "      <td>[shop_membership, coffee_shop, loan_1]</td>\n",
       "      <td>It contains members, levels, and purchase data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Phones with Memory_in_G &gt;= 128 and total stock...</td>\n",
       "      <td>phone_market</td>\n",
       "      <td>phone_market</td>\n",
       "      <td>True</td>\n",
       "      <td>[phone_market, phone_1, device]</td>\n",
       "      <td>It includes Memory_in_G and stock relations ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Total stock per carrier across all markets, de...</td>\n",
       "      <td>phone_market</td>\n",
       "      <td>phone_market</td>\n",
       "      <td>True</td>\n",
       "      <td>[phone_market, device, film_rank]</td>\n",
       "      <td>It includes Carrier and Num_of_stock for total...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Engineers with a given skill who visited any a...</td>\n",
       "      <td>assets_maintenance</td>\n",
       "      <td>assets_maintenance</td>\n",
       "      <td>True</td>\n",
       "      <td>[assets_maintenance, machine_repair, scientist_1]</td>\n",
       "      <td>It includes skills and assets under maintenanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Assets and number of recorded faults, highest ...</td>\n",
       "      <td>assets_maintenance</td>\n",
       "      <td>assets_maintenance</td>\n",
       "      <td>True</td>\n",
       "      <td>[assets_maintenance, tracking_software_problem...</td>\n",
       "      <td>It contains an 'Assets' table, aligning with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Candidates with PASS assessment outcome and th...</td>\n",
       "      <td>student_assessment</td>\n",
       "      <td>student_assessment</td>\n",
       "      <td>True</td>\n",
       "      <td>[student_assessment, candidate_poll, e_learning]</td>\n",
       "      <td>It contains Candidates and Candidate_Assessmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Total treatment cost per dog and the owner's f...</td>\n",
       "      <td>dog_kennels</td>\n",
       "      <td>dog_kennels</td>\n",
       "      <td>True</td>\n",
       "      <td>[dog_kennels, pets_1, hospital_1]</td>\n",
       "      <td>It contains Owners and Dogs tables, allowing f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Number of treatments per breed and average tre...</td>\n",
       "      <td>dog_kennels</td>\n",
       "      <td>dog_kennels</td>\n",
       "      <td>True</td>\n",
       "      <td>[dog_kennels, pets_1, hospital_1]</td>\n",
       "      <td>It includes breeds and treatments, allowing fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>People employed at any company in the year 201...</td>\n",
       "      <td>company_employee</td>\n",
       "      <td>company_employee</td>\n",
       "      <td>True</td>\n",
       "      <td>[company_employee, gas_company, company_1]</td>\n",
       "      <td>It contains employment data for people and com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Farm with the highest Total_Cattle in the most...</td>\n",
       "      <td>farm</td>\n",
       "      <td>farm</td>\n",
       "      <td>True</td>\n",
       "      <td>[farm, geo, county_public_safety]</td>\n",
       "      <td>It contains Total_Cattle and relevant year dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>For each farm, list Year and total pigs and co...</td>\n",
       "      <td>farm</td>\n",
       "      <td>farm</td>\n",
       "      <td>True</td>\n",
       "      <td>[farm, csu_1, county_public_safety]</td>\n",
       "      <td>Schema includes Year, Pigs, and Cows, matching...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Assets involved in events and the related Loca...</td>\n",
       "      <td>solvency_ii</td>\n",
       "      <td>solvency_ii</td>\n",
       "      <td>True</td>\n",
       "      <td>[solvency_ii, local_govt_and_lot, local_govt_i...</td>\n",
       "      <td>It includes both Assets and Events with relate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Swimmer with the best Time and the city of the...</td>\n",
       "      <td>swimming</td>\n",
       "      <td>swimming</td>\n",
       "      <td>True</td>\n",
       "      <td>[swimming, city_record, farm]</td>\n",
       "      <td>It contains swimmer times and stadium city, fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Debates with Num_of_Audience &gt; 1000 and the ag...</td>\n",
       "      <td>debate</td>\n",
       "      <td>debate</td>\n",
       "      <td>True</td>\n",
       "      <td>[debate, candidate_poll, performance_attendance]</td>\n",
       "      <td>Schema includes Num_of_Audience and Age of deb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>List friends of 'Alice' in the year 2015.</td>\n",
       "      <td>network_2</td>\n",
       "      <td>network_2</td>\n",
       "      <td>True</td>\n",
       "      <td>[network_2, student_1, network_1]</td>\n",
       "      <td>It has the required PersonFriend schema to fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Students living in dorms with the amenity 'Gym'.</td>\n",
       "      <td>dorm_1</td>\n",
       "      <td>dorm_1</td>\n",
       "      <td>True</td>\n",
       "      <td>[dorm_1, protein_institute, gymnast]</td>\n",
       "      <td>Schema includes 'Dorm_amenity' and 'Has_amenit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Editors older than 50 serving on any journal c...</td>\n",
       "      <td>journal_committee</td>\n",
       "      <td>journal_committee</td>\n",
       "      <td>True</td>\n",
       "      <td>[journal_committee, academic, decoration_compe...</td>\n",
       "      <td>It contains editors and journal themes, allowi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Captains and their ship names for ships built ...</td>\n",
       "      <td>ship_1</td>\n",
       "      <td>ship_1</td>\n",
       "      <td>True</td>\n",
       "      <td>[ship_1, ship_mission, battle_death]</td>\n",
       "      <td>It includes both captains and ships with built...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Artworks that won at a festival and the festiv...</td>\n",
       "      <td>entertainment_awards</td>\n",
       "      <td>entertainment_awards</td>\n",
       "      <td>True</td>\n",
       "      <td>[entertainment_awards, theme_gallery, music_4]</td>\n",
       "      <td>It includes festival details and artwork nomin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Students who have the allergy type 'Peanut'.</td>\n",
       "      <td>allergy_1</td>\n",
       "      <td>allergy_1</td>\n",
       "      <td>True</td>\n",
       "      <td>[allergy_1, pets_1, student_1]</td>\n",
       "      <td>Schema includes Allergy_Type and Has_Allergy, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Students who own a pet of type 'Cat'.</td>\n",
       "      <td>pets_1</td>\n",
       "      <td>pets_1</td>\n",
       "      <td>True</td>\n",
       "      <td>[pets_1, dog_kennels, allergy_1]</td>\n",
       "      <td>Schema includes Pets with PetType, directly ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Bookings returned_late_yn = 'Y' and the custom...</td>\n",
       "      <td>products_for_hire</td>\n",
       "      <td>products_for_hire</td>\n",
       "      <td>True</td>\n",
       "      <td>[products_for_hire, inn_1, cre_Drama_Workshop_...</td>\n",
       "      <td>It contains 'Bookings' and 'Customers' with re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Candidates and their support rates grouped by ...</td>\n",
       "      <td>candidate_poll</td>\n",
       "      <td>candidate_poll</td>\n",
       "      <td>True</td>\n",
       "      <td>[candidate_poll, voter_1, election]</td>\n",
       "      <td>Schema includes Poll_Source and Support_rate, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Top 5 customers by total invoice amount in Chi...</td>\n",
       "      <td>chinook_1</td>\n",
       "      <td>chinook_1</td>\n",
       "      <td>True</td>\n",
       "      <td>[customers_and_invoices, chinook_1, tracking_o...</td>\n",
       "      <td>It contains 'Invoice' and 'Customer' tables wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Browsers compatible since year &gt;= 2015 for acc...</td>\n",
       "      <td>browser_web</td>\n",
       "      <td>browser_web</td>\n",
       "      <td>True</td>\n",
       "      <td>[browser_web, phone_1, formula_1]</td>\n",
       "      <td>Schema includes 'accelerator' and 'compatible_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Trains on railway named 'Trans-Australia' and ...</td>\n",
       "      <td>railway</td>\n",
       "      <td>railway</td>\n",
       "      <td>True</td>\n",
       "      <td>[railway, train_station, station_weather]</td>\n",
       "      <td>It contains relevant tables for trains and man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Rooms with maxOccupancy &gt; 4 and total reserved...</td>\n",
       "      <td>inn_1</td>\n",
       "      <td>inn_1</td>\n",
       "      <td>True</td>\n",
       "      <td>[inn_1, apartment_rentals, dorm_1]</td>\n",
       "      <td>It contains Rooms with maxOccupancy and Reserv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Visitors who spent more than 100 at any museum...</td>\n",
       "      <td>museum_visit</td>\n",
       "      <td>museum_visit</td>\n",
       "      <td>True</td>\n",
       "      <td>[museum_visit, cre_Theme_park, theme_gallery]</td>\n",
       "      <td>It contains relevant tables for museums and vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Courses under subject 'Math' and enrolled stud...</td>\n",
       "      <td>e_learning</td>\n",
       "      <td>e_learning</td>\n",
       "      <td>True</td>\n",
       "      <td>[e_learning, student_transcripts_tracking, col...</td>\n",
       "      <td>It contains Courses and Subjects tables, allow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  \\\n",
       "0   Instructors with salary > 100000 and their dep...   \n",
       "1   Students and their total credits (tot_cred), d...   \n",
       "2   For each customer, compute total order value a...   \n",
       "3   Total value purchased per supplier (Product_Su...   \n",
       "4   Students registered for a course but with no a...   \n",
       "5     Count events per Channel_ID and list the top 5.   \n",
       "6   List each customer’s total checking+saving bal...   \n",
       "7   Which customer has the highest savings balance...   \n",
       "8   Show customers and total transaction count per...   \n",
       "9   Albums released after 2015 with their label an...   \n",
       "10  Songs with rating >= 9 and their genres and ar...   \n",
       "11  Artists whose songs had Weeks_on_Top >= 8 alon...   \n",
       "12  Courses with >=4 credits and the number of sec...   \n",
       "13  Flights with origin 'Dallas' and destination '...   \n",
       "14  List routes with codeshare='Y' and show airlin...   \n",
       "15  Flights from AirportCode 'DFW' to 'LAX' with a...   \n",
       "16  For each operate_company, count total flights ...   \n",
       "17  Body builder with the highest Total and their ...   \n",
       "18  Races held at tracks with Seating > 50000 and ...   \n",
       "19  Clubs with the most Gold medals and their Tota...   \n",
       "20  Papers written by author last name 'Smith' and...   \n",
       "21  For each domain, count publications after year...   \n",
       "22          Top 5 keywords by number of publications.   \n",
       "23  For each city, list GDP and Regional_Populatio...   \n",
       "24  Average July temperature for cities that hoste...   \n",
       "25  Stations with wind_speed_mph > 20 on 'Monday' ...   \n",
       "26  Election rows for County_name 'Montgomery' inc...   \n",
       "27  Count of events per Service_Type_Code in Alaba...   \n",
       "28      Medicines that interact with enzyme 'CYP3A4'.   \n",
       "29  Customers with an available policy and settlem...   \n",
       "30  Stores that sell products with dpi > 600 and t...   \n",
       "31  Members with Level >= 3 and total pounds spent...   \n",
       "32  Phones with Memory_in_G >= 128 and total stock...   \n",
       "33  Total stock per carrier across all markets, de...   \n",
       "34  Engineers with a given skill who visited any a...   \n",
       "35  Assets and number of recorded faults, highest ...   \n",
       "36  Candidates with PASS assessment outcome and th...   \n",
       "37  Total treatment cost per dog and the owner's f...   \n",
       "38  Number of treatments per breed and average tre...   \n",
       "39  People employed at any company in the year 201...   \n",
       "40  Farm with the highest Total_Cattle in the most...   \n",
       "41  For each farm, list Year and total pigs and co...   \n",
       "42  Assets involved in events and the related Loca...   \n",
       "43  Swimmer with the best Time and the city of the...   \n",
       "44  Debates with Num_of_Audience > 1000 and the ag...   \n",
       "45          List friends of 'Alice' in the year 2015.   \n",
       "46   Students living in dorms with the amenity 'Gym'.   \n",
       "47  Editors older than 50 serving on any journal c...   \n",
       "48  Captains and their ship names for ships built ...   \n",
       "49  Artworks that won at a festival and the festiv...   \n",
       "50       Students who have the allergy type 'Peanut'.   \n",
       "51              Students who own a pet of type 'Cat'.   \n",
       "52  Bookings returned_late_yn = 'Y' and the custom...   \n",
       "53  Candidates and their support rates grouped by ...   \n",
       "54  Top 5 customers by total invoice amount in Chi...   \n",
       "55  Browsers compatible since year >= 2015 for acc...   \n",
       "56  Trains on railway named 'Trans-Australia' and ...   \n",
       "57  Rooms with maxOccupancy > 4 and total reserved...   \n",
       "58  Visitors who spent more than 100 at any museum...   \n",
       "59  Courses under subject 'Math' and enrolled stud...   \n",
       "\n",
       "                    expected_db                     picked_db  correct  \\\n",
       "0                     college_2                     college_1    False   \n",
       "1                     college_2                     college_1    False   \n",
       "2              department_store               tracking_orders    False   \n",
       "3              department_store  products_gen_characteristics    False   \n",
       "4            student_assessment                    e_learning    False   \n",
       "5                   solvency_ii                 program_share    False   \n",
       "6                  small_bank_1                  small_bank_1     True   \n",
       "7                  small_bank_1                  small_bank_1     True   \n",
       "8   customers_card_transactions   customers_card_transactions     True   \n",
       "9                       music_2                       music_2     True   \n",
       "10                      music_1                       music_1     True   \n",
       "11                      music_4                       music_4     True   \n",
       "12                    college_2                     college_2     True   \n",
       "13                     flight_1                      flight_1     True   \n",
       "14                     flight_4                      flight_4     True   \n",
       "15                     flight_2                      flight_2     True   \n",
       "16               flight_company                flight_company     True   \n",
       "17                 body_builder                  body_builder     True   \n",
       "18                   race_track                    race_track     True   \n",
       "19           sports_competition            sports_competition     True   \n",
       "20                       icfp_1                        icfp_1     True   \n",
       "21                     academic                      academic     True   \n",
       "22                     academic                      academic     True   \n",
       "23                  city_record                   city_record     True   \n",
       "24                  city_record                   city_record     True   \n",
       "25              station_weather               station_weather     True   \n",
       "26                     election                      election     True   \n",
       "27        local_govt_in_alabama         local_govt_in_alabama     True   \n",
       "28  medicine_enzyme_interaction   medicine_enzyme_interaction     True   \n",
       "29               insurance_fnol                insurance_fnol     True   \n",
       "30                store_product                 store_product     True   \n",
       "31              shop_membership               shop_membership     True   \n",
       "32                 phone_market                  phone_market     True   \n",
       "33                 phone_market                  phone_market     True   \n",
       "34           assets_maintenance            assets_maintenance     True   \n",
       "35           assets_maintenance            assets_maintenance     True   \n",
       "36           student_assessment            student_assessment     True   \n",
       "37                  dog_kennels                   dog_kennels     True   \n",
       "38                  dog_kennels                   dog_kennels     True   \n",
       "39             company_employee              company_employee     True   \n",
       "40                         farm                          farm     True   \n",
       "41                         farm                          farm     True   \n",
       "42                  solvency_ii                   solvency_ii     True   \n",
       "43                     swimming                      swimming     True   \n",
       "44                       debate                        debate     True   \n",
       "45                    network_2                     network_2     True   \n",
       "46                       dorm_1                        dorm_1     True   \n",
       "47            journal_committee             journal_committee     True   \n",
       "48                       ship_1                        ship_1     True   \n",
       "49         entertainment_awards          entertainment_awards     True   \n",
       "50                    allergy_1                     allergy_1     True   \n",
       "51                       pets_1                        pets_1     True   \n",
       "52            products_for_hire             products_for_hire     True   \n",
       "53               candidate_poll                candidate_poll     True   \n",
       "54                    chinook_1                     chinook_1     True   \n",
       "55                  browser_web                   browser_web     True   \n",
       "56                      railway                       railway     True   \n",
       "57                        inn_1                         inn_1     True   \n",
       "58                 museum_visit                  museum_visit     True   \n",
       "59                   e_learning                    e_learning     True   \n",
       "\n",
       "                                           candidates  \\\n",
       "0       [department_management, college_1, student_1]   \n",
       "1   [student_transcripts_tracking, college_1, stud...   \n",
       "2   [tracking_orders, customers_and_invoices, cust...   \n",
       "3   [products_gen_characteristics, manufactory_1, ...   \n",
       "4   [e_learning, student_assessment, student_trans...   \n",
       "5                [program_share, tvshow, news_report]   \n",
       "6   [small_bank_1, loan_1, customers_card_transact...   \n",
       "7   [small_bank_1, loan_1, customers_card_transact...   \n",
       "8   [customers_card_transactions, customers_and_in...   \n",
       "9                         [music_2, music_4, music_1]   \n",
       "10                        [music_1, music_4, music_2]   \n",
       "11                         [music_4, singer, music_1]   \n",
       "12  [college_1, student_transcripts_tracking, coll...   \n",
       "13                     [flight_4, flight_2, flight_1]   \n",
       "14                [flight_4, flight_2, program_share]   \n",
       "15               [flight_2, flight_4, flight_company]   \n",
       "16               [flight_company, flight_1, flight_2]   \n",
       "17              [body_builder, gymnast, poker_player]   \n",
       "18                      [race_track, formula_1, farm]   \n",
       "19        [sports_competition, riding_club, swimming]   \n",
       "20                        [icfp_1, academic, scholar]   \n",
       "21                         [academic, book_2, icfp_1]   \n",
       "22                        [academic, scholar, icfp_1]   \n",
       "23                        [world_1, city_record, geo]   \n",
       "24                      [city_record, farm, soccer_1]   \n",
       "25           [station_weather, train_station, bike_1]   \n",
       "26  [election, election_representative, county_pub...   \n",
       "27  [local_govt_in_alabama, local_govt_and_lot, co...   \n",
       "28  [medicine_enzyme_interaction, hospital_1, cust...   \n",
       "29  [insurance_fnol, insurance_policies, insurance...   \n",
       "30  [store_product, product_catalog, products_gen_...   \n",
       "31             [shop_membership, coffee_shop, loan_1]   \n",
       "32                    [phone_market, phone_1, device]   \n",
       "33                  [phone_market, device, film_rank]   \n",
       "34  [assets_maintenance, machine_repair, scientist_1]   \n",
       "35  [assets_maintenance, tracking_software_problem...   \n",
       "36   [student_assessment, candidate_poll, e_learning]   \n",
       "37                  [dog_kennels, pets_1, hospital_1]   \n",
       "38                  [dog_kennels, pets_1, hospital_1]   \n",
       "39         [company_employee, gas_company, company_1]   \n",
       "40                  [farm, geo, county_public_safety]   \n",
       "41                [farm, csu_1, county_public_safety]   \n",
       "42  [solvency_ii, local_govt_and_lot, local_govt_i...   \n",
       "43                      [swimming, city_record, farm]   \n",
       "44   [debate, candidate_poll, performance_attendance]   \n",
       "45                  [network_2, student_1, network_1]   \n",
       "46               [dorm_1, protein_institute, gymnast]   \n",
       "47  [journal_committee, academic, decoration_compe...   \n",
       "48               [ship_1, ship_mission, battle_death]   \n",
       "49     [entertainment_awards, theme_gallery, music_4]   \n",
       "50                     [allergy_1, pets_1, student_1]   \n",
       "51                   [pets_1, dog_kennels, allergy_1]   \n",
       "52  [products_for_hire, inn_1, cre_Drama_Workshop_...   \n",
       "53                [candidate_poll, voter_1, election]   \n",
       "54  [customers_and_invoices, chinook_1, tracking_o...   \n",
       "55                  [browser_web, phone_1, formula_1]   \n",
       "56          [railway, train_station, station_weather]   \n",
       "57                 [inn_1, apartment_rentals, dorm_1]   \n",
       "58      [museum_visit, cre_Theme_park, theme_gallery]   \n",
       "59  [e_learning, student_transcripts_tracking, col...   \n",
       "\n",
       "                                           llm_reason  \n",
       "0   It includes EMPLOYEE and DEPARTMENT tables, al...  \n",
       "1   Contains 'STUDENT' and 'STU_HRS' for total cre...  \n",
       "2   It includes Orders and Customers, allowing for...  \n",
       "3   No other candidate has a relevant schema for t...  \n",
       "4   It includes Students and Student_Course_Enrolm...  \n",
       "5   Contains Channel_ID and relevant broadcast tab...  \n",
       "6   It has the required accounts and balances for ...  \n",
       "7   It contains savings and checking balances link...  \n",
       "8   It contains relevant tables for customers and ...  \n",
       "9   Contains Albums with Year, Label, and Type mat...  \n",
       "10  It includes songs with ratings, genres, and ar...  \n",
       "11  Schema includes Weeks_on_Top and Issue_Date, m...  \n",
       "12  Schema includes 'course' with credits and 'sec...  \n",
       "13  Schema includes 'origin' and 'destination' mat...  \n",
       "14  Schema includes routes with codeshare and airl...  \n",
       "15  It directly includes flights, airports, and ai...  \n",
       "16  It contains operate_company and flight tables ...  \n",
       "17  Schema includes Total and Birth_Place, matchin...  \n",
       "18  It includes track seating and location, direct...  \n",
       "19  It contains Gold and Total medal counts with n...  \n",
       "20  Schema includes Authors and Papers with necess...  \n",
       "21  Schema includes publications and domains, allo...  \n",
       "22  Contains 'keyword' and 'publication' tables ne...  \n",
       "23  It contains GDP and Regional_Population with t...  \n",
       "24  It contains temperature data and match hosting...  \n",
       "25  It includes wind_speed_mph and necessary relat...  \n",
       "26  Schema includes County_name and District, matc...  \n",
       "27  It contains Service_Type_Code and Events, allo...  \n",
       "28  Schema includes enzyme interactions, directly ...  \n",
       "29  It includes policies and settlements, directly...  \n",
       "30  It contains 'dpi' and relates stores to produc...  \n",
       "31  It contains members, levels, and purchase data...  \n",
       "32  It includes Memory_in_G and stock relations ne...  \n",
       "33  It includes Carrier and Num_of_stock for total...  \n",
       "34  It includes skills and assets under maintenanc...  \n",
       "35  It contains an 'Assets' table, aligning with t...  \n",
       "36  It contains Candidates and Candidate_Assessmen...  \n",
       "37  It contains Owners and Dogs tables, allowing f...  \n",
       "38  It includes breeds and treatments, allowing fo...  \n",
       "39  It contains employment data for people and com...  \n",
       "40  It contains Total_Cattle and relevant year dat...  \n",
       "41  Schema includes Year, Pigs, and Cows, matching...  \n",
       "42  It includes both Assets and Events with relate...  \n",
       "43  It contains swimmer times and stadium city, fu...  \n",
       "44  Schema includes Num_of_Audience and Age of deb...  \n",
       "45  It has the required PersonFriend schema to fin...  \n",
       "46  Schema includes 'Dorm_amenity' and 'Has_amenit...  \n",
       "47  It contains editors and journal themes, allowi...  \n",
       "48  It includes both captains and ships with built...  \n",
       "49  It includes festival details and artwork nomin...  \n",
       "50  Schema includes Allergy_Type and Has_Allergy, ...  \n",
       "51  Schema includes Pets with PetType, directly ma...  \n",
       "52  It contains 'Bookings' and 'Customers' with re...  \n",
       "53  Schema includes Poll_Source and Support_rate, ...  \n",
       "54  It contains 'Invoice' and 'Customer' tables wi...  \n",
       "55  Schema includes 'accelerator' and 'compatible_...  \n",
       "56  It contains relevant tables for trains and man...  \n",
       "57  It contains Rooms with maxOccupancy and Reserv...  \n",
       "58  It contains relevant tables for museums and vi...  \n",
       "59  It contains Courses and Subjects tables, allow...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Batch evaluation with LLM pick (OpenAI embeddings → top-k; LLM chooses best)\n",
    "import pandas as pd\n",
    "\n",
    "# Pick the agent/cards you actually have in memory\n",
    "AGENT = (\n",
    "    agent_openai_aug if 'agent_openai_aug' in globals()\n",
    "    else agent_openai_qas if 'agent_openai_qas' in globals()\n",
    "    else agent_openai\n",
    ")\n",
    "CARDS = cards_aug if 'cards_aug' in globals() else cards\n",
    "DB_IDS = db_ids\n",
    "\n",
    "# Ensure the LLM reranker exists\n",
    "assert 'llm_pick_best_db' in globals(), \"Define llm_pick_best_db(...) first.\"\n",
    "\n",
    "LLM_MODEL = \"gpt-4o-mini\"\n",
    "TOP_K = 3\n",
    "POOL = 50\n",
    "\n",
    "rows = []\n",
    "for q, expected in tests:\n",
    "    # 1) retrieve candidates via embeddings\n",
    "    prop = AGENT.propose(q, top=TOP_K, pool=POOL)\n",
    "    cands = prop.get(\"candidates\", [])\n",
    "    top_cands = [c[\"db_id\"] for c in cands]\n",
    "\n",
    "    # handle edge case: no candidates\n",
    "    if not cands:\n",
    "        rows.append({\n",
    "            \"query\": q,\n",
    "            \"expected_db\": expected,\n",
    "            \"picked_db\": None,\n",
    "            \"correct\": False,\n",
    "            \"candidates\": [],\n",
    "            \"llm_reason\": \"no candidates from proposer\",\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # 2) let the LLM pick the best among candidates\n",
    "    decision = llm_pick_best_db(q, cands, CARDS, DB_IDS, model=LLM_MODEL)\n",
    "    picked = decision.get(\"best_db_id\", \"\")\n",
    "    reason = decision.get(\"reason\", \"\")\n",
    "\n",
    "    rows.append({\n",
    "        \"query\": q,\n",
    "        \"expected_db\": expected,\n",
    "        \"picked_db\": picked,\n",
    "        \"correct\": (picked == expected),\n",
    "        \"candidates\": top_cands,\n",
    "        \"llm_reason\": reason[:200],\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "acc = df[\"correct\"].mean() if len(df) else 0.0\n",
    "print(f\"\\nAccuracy: {df['correct'].sum()} / {len(df)} = {acc:.3f}\")\n",
    "\n",
    "# Show mistakes first, then correct\n",
    "df_sorted = pd.concat([df[~df.correct], df[df.correct]], ignore_index=True)\n",
    "display(df_sorted[[\"query\",\"expected_db\",\"picked_db\",\"correct\",\"candidates\",\"llm_reason\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c417563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f00e1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
